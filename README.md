<<<<<<< Updated upstream
# Cloud Deployment Log â€” FastAPI ML Model on AWS ECS Fargate

This document records **every step** taken to deploy a FastAPI machine-learning application to the cloud using **Docker + AWS ECR + ECS Fargate + Load Balancer**.  
All sensitive information (AWS Access Keys, Secrets, etc.) has been removed.

---
# âœ… Architecture
<img width="1024" height="1024" alt="Architecture" src="https://github.com/user-attachments/assets/6a7f80e2-0338-4814-b3a7-8c2e8ae204b0" />





# âœ… 1. Create Python Virtual Environment

```
python -m venv .venv
```

Activate it:

```
.\.venv\Scripts\activate
```

---

# âœ… 2. Create `requirements.txt`

Include the necessary packages:

```
fastapi
uvicorn[standard]
joblib
numpy
scikit-learn
jinja2
python-multipart
```

---

# âœ… 3. Create Dockerfile

Your Dockerfile should:

- Pull a lightweight Python image (e.g., python:3.11-slim)
- Set `/app` as the working directory
- Install all dependencies from `requirements.txt`
- Copy the FastAPI code, ML model, and templates
- Run Uvicorn on port 8000

---

# âœ… 4. Create `.dockerignore`

This reduces container size by excluding unnecessary folders:

```
.venv/
__pycache__/
*.pyc
.git
.gitignore
.env
```

---

# âœ… 5. Build the Docker Image

Build locally:

```
docker build -t iris-ml-api .
```

This will:

- Pull python:3.11-slim (first time only)
- Install requirements
- Copy your application

---

# âœ… 6. Run Container Locally

Test your image:

```
docker run -p 8000:8000 iris-ml-api
```

Visit:

```
http://localhost:8000/
```

---

# âœ… 7. Push Your Image to AWS ECR

## 7.1 Install AWS CLI

Download AWS CLI installer:  
https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

Configure CLI:

```
aws configure
```

Enter:
- Access Key ID  
- Secret Key  
- Default region (ex: ca-central-1)

---

## 7.2 Create IAM User (in Console)

Create user with **programmatic access**.

Attach permissions:

- `AmazonEC2ContainerRegistryFullAccess`
- `AmazonECS_FullAccess`
- `CloudWatchLogsFullAccess`

Save access keys (DO NOT include in README).

---

## 7.3 Create ECR Repository

1. AWS Console â†’ ECR â†’ Create repository  
2. Repository name: `iris-ml-api`  
3. Copy the `repository URI`

Example:

```
414691912275.dkr.ecr.ca-central-1.amazonaws.com/iris-ml-api
```

---

## 7.4 Authenticate Docker to ECR

```
aws ecr get-login-password --region ca-central-1 | docker login --username AWS --password-stdin 414691912275.dkr.ecr.ca-central-1.amazonaws.com
```

---

## 7.5 Tag and Push Your Image

Tag image:

```
docker tag iris-ml-api:latest 414691912275.dkr.ecr.ca-central-1.amazonaws.com/iris-ml-api:latest
```

Push image:

```
docker push 414691912275.dkr.ecr.ca-central-1.amazonaws.com/iris-ml-api:latest
```

Confirm in AWS Console â†’ Image with tag `latest` appears.

---

# âœ… Step 8 â€” Create ECS Cluster (Fargate)

### IAM Requirement:
Attach:

```
AmazonEC2ContainerServiceRole
```

### Create the Cluster:

1. ECS â†’ Clusters â†’ Create cluster  
2. Select **Fargate only**  
3. Cluster name: `iris-ml-cluster`  
4. Finish creation

---

# âœ… Step 9 â€” Create ECS Task Definition

### Task Definition Details:

- Launch type: **AWS Fargate**
- OS: Linux
- CPU: **0.25 vCPU**
- Memory: **0.5 GB**
- Container settings:
  - Image URI: your ECR image
  - Port mapping: **8000**

This defines:

- CPU & memory for your container  
- Which Docker image to run  
- Networking & runtime configuration  

---

# âœ… Step 10 â€” Create ECS Service (cluster â†’ service â†’ running container)

From your cluster:

1. ECS â†’ Cluster â†’ *Your cluster*
2. Go to "Services" â†’ "Create"
3. Service name: `iris-ml-service`
4. Launch type: **Fargate**
5. Task definition: select the one created
6. Desired tasks: **1**

---

# âœ… Step 11 â€” Configure Networking & Load Balancer

### VPC
- Use **default VPC**

### Subnets
- Select **two public subnets**

### Security Group
Create a new SG:

Inbound rules:

| Type | Port | Source |
|------|-------|--------|
| HTTP | 80 | 0.0.0.0/0 |

### Load Balancer
- Create new **Application Load Balancer**
- Internet-facing
- Listener: **HTTP : 80**

### Target Group
- Create new TG
- Port: **8000**
- Health check path: `/`

### Auto-assign Public IP
âœ” Enabled

Create service.

---

# âœ… Step 12 â€” Get Public URL

1. Go to **EC2 â†’ Load Balancers**
2. Select: `iris-ml-lb`
3. Copy DNS name

Example:

```
http://iris-ml-lb-123456.ca-central-1.elb.amazonaws.com/
```

Open in browser â†’ FastAPI UI should load.

---

# â— If Load Balancer Shows 504 Timeout

Check **Target Group â†’ Targets â†’ Health details**

If showing **"Request timed out"**, fix by editing the **task security group**:

Add inbound rule:

```
Type: Custom TCP
Port range: 8000
Source: 0.0.0.0/0
```

After saving, target will become **Healthy**.

---
=======
ğŸ“ TeleLink Communications - Customer Analytics Platform

An AI-powered customer churn prediction and lifetime value estimation system for telecommunications providers.

ğŸ¯ Project Overview
TeleLink Communications serves over 1.2 million customers across the United States and faces three critical challenges:
 + Rising customer churn rates (14.2%)
 + Difficulty in accurate revenue forecasting
 + Unpredictable usage patterns affecting operational costs

This platform uses Machine Learning to:

Predict customer churn with up to 95% accuracy
Estimate Customer Lifetime Value (CLV) for strategic planning
Provide actionable recommendations for retention strategies


ğŸ—ï¸ System Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER'S BROWSER                           â”‚
â”‚                   (Accesses via Web Browser)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ HTTP Request
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       AWS EC2 INSTANCE                          â”‚
â”‚                        (t2.micro)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              DOCKER CONTAINER                             â”‚ â”‚
â”‚  â”‚                                                           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  â”‚  â”‚           FASTAPI APPLICATION                   â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                                                 â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  â”‚   Frontend   â”‚      â”‚   Backend API     â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  â”‚              â”‚      â”‚                   â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  index.html  â”‚â—„â”€â”€â”€â”€â–ºâ”‚   backend.py     â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  (Static)    â”‚      â”‚   (FastAPI)      â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                                  â”‚            â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                                  â–¼            â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚   ML MODELS      â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚                  â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚ 1. Churn Model   â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚    (Random       â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚     Forest)      â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚                  â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚ 2. CLV Model     â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚    (Linear       â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â”‚     Regression)  â”‚  â”‚    â”‚ â”‚
â”‚  â”‚  â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  Port 8000 (Internal) â”€â”€â–º Port 80 (External)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Data Flow
User Input (Customer Data)
         â”‚
         â–¼
   Web Browser (HTML/JS)
         â”‚
         â–¼
   HTTP POST Request
         â”‚
         â–¼
   FastAPI Backend
         â”‚
         â”œâ”€â”€â–º Validate Input (Pydantic)
         â”‚
         â”œâ”€â”€â–º Preprocess Data (Sklearn Pipeline)
         â”‚
         â”œâ”€â”€â–º Load ML Models (.pkl files)
         â”‚
         â”œâ”€â”€â–º Make Predictions
         â”‚         â”œâ”€â–º Churn Probability
         â”‚         â””â”€â–º Customer Lifetime Value
         â”‚
         â”œâ”€â”€â–º Generate Risk Level (Low/Medium/High)
         â”‚
         â”œâ”€â”€â–º Create Recommendation
         â”‚
         â–¼
   JSON Response
         â”‚
         â–¼
   Display Results in Browser

ğŸš€ Quick Start Guide
Prerequisites
What You Need:

âœ… AWS Account (free tier works!)
âœ… Basic command line knowledge
âœ… SSH key pair for EC2
âœ… 15 minutes of your time

What's Included:

+ 2 Pre-trained ML models
+ Professional web interface
+ Automated deployment scripts
+ Real-time predictions


ğŸ“¦ Installation
Option 1: Local Development (Testing)
Step 1: Clone Repository
bashgit clone https://github.com/Andres-lng/ML-DL-FINALPROJECT.git
cd ML-DL-FINALPROJECT
Step 2: Install Dependencies
bashpip install -r requirements.txt
Step 3: Run Application
bashpython backend.py
Step 4: Access Application
Open browser: http://localhost:8000

Option 2: AWS EC2 Deployment (Production Demo)
Step 1: Launch EC2 Instance

Go to AWS Console â†’ EC2 â†’ Launch Instance
Configure:

Name: telelink-demo
AMI: Amazon Linux 2023
Type: t2.micro (Free Tier)
Key Pair: Create or select existing
Security Group: Allow HTTP (80), HTTPS (443), SSH (22)


Click Launch

Step 2: Connect to EC2
ssh -i your-key.pem ec2-user@YOUR_EC2_IP
Step 3: Clone Repository
[git clone ML-DL-FINALPROJECT](https://github.com/Andres-lng/ML-DL-FINALPROJECT.git)
cd ML-DL-FINALPROJECT
Step 4: Initial Setup (One-Time)
bash setup-ec2.sh
Step 5: Deploy Application
bash deploy.sh
Step 6: Access Your Application
http://YOUR_EC2_PUBLIC_IP
That's it! ğŸ‰ Your application is now live!

ğŸ“ Project Structure
telelink-analytics/
â”‚
â”œâ”€â”€ ğŸ“„ backend.py                    # FastAPI application (Backend + Frontend server)
â”œâ”€â”€ ğŸ“„ index.html                    # Web interface (Frontend)
â”œâ”€â”€ ğŸ¤– best_churn_model.pkl         # Trained Random Forest model
â”œâ”€â”€ ğŸ¤– best_clv_model.pkl           # Trained Linear Regression model
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”‚
â”œâ”€â”€ ğŸ³ Dockerfile                    # Docker container configuration
â”œâ”€â”€ ğŸ“„ .dockerignore                 # Files to exclude from Docker
â”‚
â”œâ”€â”€ ğŸš€ setup-ec2.sh                  # EC2 initial setup script
â”œâ”€â”€ ğŸš€ deploy.sh                     # Deployment script
â”‚
â”œâ”€â”€ ğŸ“Š FinalProject_ANLT202.ipynb   # Model training notebook
â”‚
â””â”€â”€ ğŸ“– README.md                     # This file

ğŸ”§ Technology Stack
Backend

FastAPI - Modern Python web framework
Scikit-learn - Machine learning library
Pandas - Data manipulation
Joblib - Model serialization
Uvicorn - ASGI server

Frontend

HTML5 - Structure
CSS3 - Styling (Responsive design)
Vanilla JavaScript - Interactivity (No frameworks!)

Machine Learning

Random Forest Classifier - Churn prediction (95% accuracy)
Linear Regression - CLV estimation (RÂ² = 0.89)
SMOTE - Handling imbalanced data
StandardScaler - Feature normalization

Deployment

Docker - Containerization
AWS EC2 - Cloud hosting
Amazon Linux 2023 - Operating system


ğŸ“Š Machine Learning Models
Model 1: Churn Prediction (Classification)
Algorithm: Tuned Random Forest Classifier
Performance Metrics:

âœ… Accuracy: 95.2%
âœ… Precision: 93.8%
âœ… Recall: 89.4%
âœ… F1-Score: 91.5%

Features Used:

Account length
Call volumes (day/evening/night/international)
Customer service calls
International plan status
Voicemail plan status
Geographic data (state, area code)

Output:

Churn probability (0-100%)
Risk level (Low/Medium/High)
Confidence score


Model 2: Customer Lifetime Value (Regression)
Algorithm: Linear Regression Pipeline
Performance Metrics:

âœ… RÂ² Score: 0.89
âœ… MAE: $2,450
âœ… RMSE: $3,120

Features Used:

Account length
Monthly charges (day/evening/night/international)
Service plan indicators
Usage patterns

Output:

Estimated CLV in dollars
Revenue forecast


ğŸ® How to Use
1. Access the Application
Open your browser and navigate to:

Local: http://localhost:8000
EC2: http://YOUR_EC2_IP

2. Enter Customer Data
Fill in the form with customer information:

Account Details: Length, state, area code
Service Plans: International plan, voicemail plan
Usage Data: Call volumes, voicemail messages
Support: Customer service calls

3. Click "Analyze Customer"
The system will:

Validate your input
Process the data
Run predictions through both models
Display results in ~1-2 seconds

4. Review Results
You'll see:

    Churn Risk: Probability and risk level
    CLV Estimate: Predicted lifetime value
    Recommendation: Specific action to take
    Confidence: Model certainty level

5. Take Action
Based on the risk level:

ğŸ”´ High Risk: Immediate retention action required
ğŸŸ¡ Medium Risk: Proactive engagement needed
ğŸŸ¢ Low Risk: Maintain regular engagement


ğŸ¯ Use Cases
For Customer Service Teams

Identify at-risk customers before they churn
Prioritize retention efforts based on CLV
Personalize customer interactions

For Marketing Teams

Target high-value customers for upselling
Design retention campaigns for at-risk segments
Optimize marketing spend based on CLV

For Executive Leadership

Forecast revenue more accurately
Make data-driven strategic decisions
Track customer health metrics in real-time

For Data Analytics Teams

Monitor model performance
Generate insights from prediction patterns
Identify key churn drivers


ğŸ” API Documentation
Once deployed, access interactive API documentation at:
http://YOUR_IP/docs
Main Endpoints
1. Health Check
httpGET /health
Response:
json{
  "status": "healthy",
  "churn_model": "loaded",
  "clv_model": "loaded",
  "api_version": "2.0.0"
}
2. Predict Customer
httpPOST /predict
Content-Type: application/json
Request:
json{
  "accountLength": 128,
  "state": "CA",
  "areaCode": "415",
  "internationalPlan": "no",
  "voiceMailPlan": "yes",
  "numberOfVmailMessages": 25,
  "totalDayCalls": 110,
  "totalEveCalls": 85,
  "totalNightCalls": 95,
  "totalIntlCalls": 3,
  "customerServiceCalls": 1
}
Response:
json{
  "churn_probability": 0.23,
  "churn_risk": "Medium",
  "estimated_clv": 32450.50,
  "recommendation": " PROACTIVE: Valuable customer showing warning signs...",
  "confidence": "High"
}
3. Get Statistics
httpGET /stats
4. Batch Predictions
httpPOST /batch-predict


ğŸ“ Contact
TeleLink Analytics Team

<div align="center">
Made with â¤ï¸ for TeleLink Communications
Empowering data-driven decisions through AI
</div>
>>>>>>> Stashed changes
